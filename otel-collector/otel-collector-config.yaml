connectors:
  spanmetrics:
    histogram:
      explicit:
        buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms]
    dimensions:
      - name: http.method
        default: GET
      - name: http.status_code
    exemplars:
      enabled: true
    exclude_dimensions: ['status.code']
    dimensions_cache_size: 1000
    aggregation_temporality: "AGGREGATION_TEMPORALITY_CUMULATIVE"
    metrics_flush_interval: 15s

receivers:
  tcplog/docker:
    listen_address: "0.0.0.0:2255"
    operators:
      - type: regex_parser
        regex: '^<([0-9]+)>[0-9]+ (?P<timestamp>[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}(\.[0-9]+)?([zZ]|([\+-])([01]\d|2[0-3]):?([0-5]\d)?)?) (?P<container_id>\S+) (?P<container_name>\S+) [0-9]+ - -( (?P<body>.*))?'
        timestamp:
          parse_from: attributes.timestamp
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      - type: move
        from: attributes["body"]
        to: body
      - type: remove
        field: attributes.timestamp
        # please remove names from below if you want to collect logs from them
      - type: filter
        id: signoz_logs_filter
        expr: 'attributes.container_name matches "^lgtm-stack-(logspout|load-hotrod|otel-collector)-1"'
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    send_batch_size: 10000
    send_batch_max_size: 11000
    timeout: 10s
  transform:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          - merge_maps(cache, ExtractPatterns(body, "^^(?P<timestamp>[^\t]+)\t(?P<severity>[^\t]+)\t(?P<source>[^\t]+)\t(?P<message>[^\t]+)\t(?P<json_msg>[^\t]+)$"), "upsert") where IsMatch(attributes["container_name"], "lgtm-stack-hotrod-1")
          - set(body, cache["message"])
          - merge_maps(cache, ParseJSON(cache["json_msg"]), "upsert") where IsMatch(cache["json_msg"], "^\\{.*\\}$")
          - set(attributes["service"], cache["service"])
          - set(severity_text, cache["severity"])
          - set(trace_id.string, cache["trace_id"])
          - set(span_id.string, cache["span_id"])
          # - set(service_name, attributes["container_name"])
  attributes:
    actions:
      - action: insert
        key: loki.attribute.labels
        value: container_name

exporters:
  logging:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200
  loki:
    endpoint: http://loki:3100/loki/api/v1/push
    default_labels_enabled:
      exporter: false
      job: true
  otlp/tempo:
    endpoint: tempo:4317
    tls:
      insecure: true
  prometheus:
    endpoint: "0.0.0.0:1234"
    namespace: test-space
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true
    add_metric_suffixes: false
    resource_to_telemetry_conversion:
      enabled: true

service:
  telemetry:
    logs:
      level: debug
  pipelines:
    logs:
      receivers:
        - tcplog/docker
        - otlp
      processors:
        - transform
        - attributes
        - batch
      exporters:
        - loki
        - logging
    metrics:
      receivers:
        - spanmetrics
      processors:
        - batch
      exporters:
        - prometheus
    traces:
      receivers:
        - jaeger
      processors:
        - batch
      exporters:
        - otlp/tempo
        - spanmetrics
